{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QONNX - Transformation passes\n",
    "--------------------------------------\n",
    "In this notebook the idea behind transformation passes in QONNX will be explained and with the help of an example the procedure of a transformation will be shown.\n",
    "\n",
    "We'll use the following utility functions to print the source code for function calls (`showSrc()`) and to visualize a network using netron (`showInNetron()`) in the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import netron\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def showSrc(what):\n",
    "    print(\"\".join(inspect.getsourcelines(what)[0]))\n",
    "\n",
    "\n",
    "def showInNetron(model_filename: str, localhost_url: str = None, port: int = None):\n",
    "    \"\"\"Shows a ONNX model file in the Jupyter Notebook using Netron.\n",
    "\n",
    "    :param model_filename: The path to the ONNX model file.\n",
    "    :type model_filename: str\n",
    "\n",
    "    :param localhost_url: The IP address used by the Jupyter IFrame to show the model.\n",
    "     Defaults to localhost.\n",
    "    :type localhost_url: str, optional\n",
    "\n",
    "    :param port: The port number used by Netron and the Jupyter IFrame to show\n",
    "     the ONNX model.  Defaults to 8081.\n",
    "    :type port: int, optional\n",
    "\n",
    "    :return: The IFrame displaying the ONNX model.\n",
    "    :rtype: IPython.lib.display.IFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        port = port or int(os.getenv(\"NETRON_PORT\", default=\"8081\"))\n",
    "    except ValueError:\n",
    "        port = 8081\n",
    "    localhost_url = localhost_url or os.getenv(\"LOCALHOST_URL\", default=\"localhost\")\n",
    "    netron.start(model_filename, address=(\"0.0.0.0\", port), browse=False)\n",
    "    return IFrame(src=f\"http://{localhost_url}:{port}/\", width=\"100%\", height=400)\n",
    "\n",
    "def download_model_from_zoo():\n",
    "    qonnx_url=\"https://github.com/fastmachinelearning/QONNX_model_zoo/raw/main/models/MNIST/Brevitas_FINN_TFC/TFC/TFC_2W2A.onnx\"\n",
    "    dl_file=\"TFC_2W2A.onnx\"\n",
    "    urllib.request.urlretrieve(qonnx_url, dl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information\n",
    "-----------------------------\n",
    "* changes (transforms) the given graph\n",
    "* input: ModelWrapper\n",
    "* returns the changed model (ModelWrapper) and flag `model_was_changed`\n",
    "\n",
    "Transformation passes have a base class and must inherit from that. Transformations are meant to be applied using .transform function from the ModelWrapper. This function makes a deep copy of the input model by default. The next cell shows .transform of ModelWrapper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .transform() from ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def transform(self, transformation, make_deepcopy=True, cleanup=True):\n",
      "        \"\"\"Applies given Transformation repeatedly until no more changes can be made\n",
      "        and returns a transformed ModelWrapper instance.\n",
      "\n",
      "        - make_deepcopy : operates on a new (deep)copy of model.\n",
      "        - cleanup : execute cleanup transformations before returning\n",
      "        \"\"\"\n",
      "        transformed_model = self\n",
      "        if make_deepcopy:\n",
      "            transformed_model = copy.deepcopy(self)\n",
      "        if self.fix_float64:\n",
      "            (transformed_model, model_was_changed) = DoubleToSingleFloat().apply(transformed_model)\n",
      "        model_was_changed = True\n",
      "        while model_was_changed:\n",
      "            (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "        if cleanup:\n",
      "            transformed_model.cleanup()\n",
      "        return transformed_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "showSrc(ModelWrapper.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function is called, the model, the name of the transformation and, if required, the flag make_deepcopy are passed. It is also possible not to make a copy of the model. In this case `make_deepcopy` must be set to False. Then the branch `if make_deepcopy:` would not be taken and no copy of the model would be made. \n",
    "\n",
    "The unchanged model is first passed to the variable `transformed_model` to pass this variable on to the transformation later. \n",
    "\n",
    "`model_was_changed` indicates whether the transformation needs to be applied more then once. Because it needs to be applied at least one time `model_was_changed` is first set to True and then depending on the return values of the transformation function the transformation can be applied more then once. \n",
    "\n",
    "**Important**: Due to the structure of this function, `model_was_changed` must be set to False at some point. Otherwise the loop is infinite.\n",
    "    \n",
    "\n",
    "Each new transformation must correspond to the scheme of the base class and contain at least the function `apply(model)`, which returns the changed model and a bool value for `model_was_changed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Base Class     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Transformation(ABC):\n",
      "    \"\"\"Transformation class all transformations are based on. Contains only\n",
      "    abstract method apply() every transformation has to fill.\"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "\n",
      "    @abstractmethod\n",
      "    def apply(self, model):\n",
      "        pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.base import Transformation\n",
    "\n",
    "showSrc(Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class is abstract class (`import ABC`) with only one abstract method (`apply()`) which gets the model as input. To show what a transformation should look like, the following example is taken from a general-purpose QONNX transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - ConvertSubToAdd\n",
    "-----------------------------\n",
    "The transformation replaces all subtraction nodes in a model with addition nodes with appropriate sign. For that an onnx model is loaded which contains one subtraction node. \n",
    "    \n",
    "Netron is used to visualize the result before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model_from_zoo()\n",
    "import onnx\n",
    "onnx_model = onnx.load('TFC_2W2A.onnx')\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "onnx_model = ModelWrapper(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'TFC_2W2A.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fca954c9050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"TFC_2W2A.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.base import Transformation\n",
    "\n",
    "class ConvertSubToAdd(Transformation):\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        for n in graph.node:\n",
    "            if n.op_type == \"Sub\":\n",
    "                A = model.get_initializer(n.input[1])\n",
    "                if A is not None:\n",
    "                    n.op_type = \"Add\"\n",
    "                    model.set_initializer(n.input[1], -A)\n",
    "        return (model, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the transformation class must be imported. Then a class can be created for the new transformation, which is derived from the base class. In this case the transformation has only the `apply()` function. \n",
    "\n",
    "All nodes are checked by first extracting the graph from the model and then iterating over the node list. With the help of .op_type the operation type of the node can be checked, if the node is a subtraction node the condition `if n.op_type == \"Sub\"` is true. It may be that the subtraction input of the node has no value, this is checked with `model.get_initializer(n.input[1])`. \n",
    "    \n",
    "    \n",
    "**Important:** As with ONNX, QONNX always assumes a certain order of inputs, this is especially important if you want to create additional custom operation nodes.\n",
    "\n",
    "When the input is initialized, the operation type of the node is converted to `\"Add\"`, this can simply be done by using the equal sign. Then the sign of the initial value must be changed. For this the ModelWrapper function `.set_initializer` can be used.\n",
    "\n",
    "At the end the changed model is returned and `model_was_changed` is set to False, because the transformation has to be executed only once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_transformed = onnx_model.transform(ConvertSubToAdd())\n",
    "onnx_model_transformed.save('/tmp/LFCW1A1_changed.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/LFCW1A1_changed.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fca948a9510>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('/tmp/LFCW1A1_changed.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Transformation\n",
    "---------------------------------\n",
    "Some of the transformations in QONNX can be performed in parallel on individual nodes to make the transformations run quicker. The following `NodeLocalTransformation` is required for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodeLocalTransformation(Transformation):\n",
      "    \"\"\"\n",
      "    Parent class for transformations, which can be executed locally to one node\n",
      "    by accessing and modifying the attributes of only that node.\n",
      "    This class can then automatically parallelize the transformation.\n",
      "    Transformations sublcassing NodeLocalTransformation must implement the\n",
      "    abstract method applyNodeLocal().\n",
      "\n",
      "    To control the degree of parallelization, specify the num_workers argument\n",
      "    in the constructor, using one of the following values:\n",
      "    * None: use NUM_DEFAULT_WORKERS environment variable\n",
      "    * 0: use all available CPU cores\n",
      "    * (any other int>0): set number of parallel workers\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, num_workers=None):\n",
      "        super().__init__()\n",
      "        if num_workers is None:\n",
      "            self._num_workers = get_num_default_workers()\n",
      "        else:\n",
      "            self._num_workers = num_workers\n",
      "        assert self._num_workers >= 0, \"Number of workers must be nonnegative.\"\n",
      "        if self._num_workers == 0:\n",
      "            self._num_workers = mp.cpu_count()\n",
      "\n",
      "    @abstractmethod\n",
      "    def applyNodeLocal(self, node):\n",
      "        pass\n",
      "\n",
      "    def apply(self, model):\n",
      "        # Remove old nodes from the current model\n",
      "        old_nodes = []\n",
      "        for i in range(len(model.graph.node)):\n",
      "            old_nodes.append(model.graph.node.pop())\n",
      "\n",
      "        # Execute transformation in parallel\n",
      "        with mp.Pool(self._num_workers) as p:\n",
      "            new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "\n",
      "        # extract nodes and check if the transformation needs to run again\n",
      "        # Note: .pop() had initially reversed the node order\n",
      "        run_again = False\n",
      "        for node, run in reversed(new_nodes_and_bool):\n",
      "            # Reattach new nodes to old model\n",
      "            model.graph.node.append(node)\n",
      "            if run is True:\n",
      "                run_again = True\n",
      "\n",
      "        return (model, run_again)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.base import NodeLocalTransformation\n",
    "\n",
    "showSrc(NodeLocalTransformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations that are to be executed in parallel must have the method `applyNodeLocal()` implemented. Please note that the transformation is only executed on a single node, the parallel transformations do not have access to the entire model or tensors. Parallelization has the advantage that especially time-consuming transformations such as compilation can be executed more effectively. \n",
    "\n",
    "To control the degree of parallelization the argument `num_workers` can be specified. The environment variable `NUM_DEFAULT_WORKERS` controls this. You can set the number of workers manually to a specific value when calling a transformation that allows parallelization. If the value is set to 0, all available CPU cores are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
